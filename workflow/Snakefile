
##### global workflow dependencies #####
# conda: "envs/global.yaml"

##### libraries #####
import os
import sys
import pandas as pd
import yaml
from snakemake.utils import min_version
from collections import defaultdict

##### set minimum snakemake version #####
min_version("8.20.1")

module_name = "dea_limma"

##### setup report #####
report: os.path.join("report", "workflow.rst")

##### load config and sample annotation sheets #####
configfile: os.path.join("config", "config.yaml")

# load annotation
annot = pd.read_csv(config['annotation'], index_col='name')
std_analyses = list(annot.index)
# check if OvA columns exists and returns non-empty indices with postfix "_OvA"
ova_analyses = [
    f"{idx}_OvA_{val}"
    for idx, cell in annot.get('OvA', pd.Series('', index=annot.index)).fillna('').loc[lambda s: s!=''].items()
    for val in cell.split('|')
]
# create list of all analyses
analyses = std_analyses + ova_analyses

std_analyses_to_ova_dict = defaultdict(list)
for ova_analysis in ova_analyses:
    std_analysis = ova_analysis.split('_OvA_')[0]
    std_analyses_to_ova_dict[std_analysis].append(ova_analysis)

# convert dictionary for parametrization of rules
annot_dict = annot.to_dict('index')
# print(annot_dict)

# load feature list paths and keep only non-empty
feature_lists = []
feature_lists_dict = config["feature_lists"]
feature_lists_dict = {k: v for k, v in feature_lists_dict.items() if v!=""}
if feature_lists_dict is not None:
    feature_lists = feature_lists + list(feature_lists_dict.keys())

result_path = os.path.join(config["result_path"], module_name)

##### target rule #####
rule all:
    input:
        results = expand(os.path.join(result_path,'{analysis}','results.csv'),
                            analysis = analyses,
                           ),
        # lmfit_objects = expand(os.path.join(result_path,'{analysis}','lmfit_object.rds'),
        #                     analysis = std_analyses,
        #                    ),
        # model_matrices = expand(os.path.join(result_path,'{analysis}','model_matrix.csv'),
        #                     analysis = std_analyses,
        #                    ),
        volcanos = expand(os.path.join(result_path,'{analysis}','plots','volcano','{feature_list}'),
                          analysis = analyses,
                          feature_list = feature_lists + ['ALL'],
                         ),
        stats = expand(os.path.join(result_path,'{analysis}','stats.csv'),
                               analysis = analyses,
                      ),
        stats_ova = expand(os.path.join(result_path,'{analysis}', 'stats_OvA.csv'),
                               analysis = std_analyses_to_ova_dict.keys(),
                      ),
        heatmaps = expand(os.path.join(result_path,'{analysis}','plots','heatmap','{feature_list}.png'),
                          analysis = analyses,
                          feature_list = feature_lists + ['FILTERED'],
                         ),
        envs = expand(os.path.join(result_path,'envs','{env}.yaml'),env=['limma','volcanos','ggplot','heatmap']),
        configs = os.path.join(result_path,'configs','{}_config.yaml'.format(config["project_name"])),
        annotations = os.path.join(result_path,'configs','{}_annot.csv'.format(config["project_name"])),
        feature_lists = expand(os.path.join(result_path,'configs','{feature_list}.txt'), feature_list = feature_lists),
    resources:
        mem_mb=config.get("mem", "16000"),
    threads: config.get("threads", 1)
    log:
        os.path.join("logs","rules","all.log"),


##### load rules #####
include: os.path.join("rules", "common.smk")
include: os.path.join("rules", "dea.smk")
include: os.path.join("rules", "visualize.smk")
include: os.path.join("rules", "envs_export.smk")
